{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "#from dateutil import parser\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import calendar\n",
    "from calendar import monthrange\n",
    "###\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Columns in data #### 2019 Dataset #### Amount of missing values differ among datasets ####\n",
    "#### Not all vars exist for alls years, selection based on availability of similar vars for each year ####\n",
    "#### Selected vars marked with X ####\n",
    " 0   id                        35554 non-null  object \n",
    " 1   external_id               24533 non-null  object \n",
    " 2   webpage_url               35554 non-null  object \n",
    " 3   logo_url                  28486 non-null  object \n",
    " 4   headline                  35554 non-null  object X\n",
    " 5   application_deadline      35554 non-null  object  X END DATE\n",
    " 6   number_of_vacancies       35550 non-null  float64 X\n",
    " 7   description               35554 non-null  object\n",
    "    'text', 'text_formatted', 'company_information', 'needs', 'requirements', 'conditions'\n",
    " 8   employment_type           35554 non-null  object \n",
    " 9   salary_type               35554 non-null  object\n",
    " 10  salary_description        22812 non-null  object \n",
    " 11  duration                  35554 non-null  object \n",
    " 12  working_hours_type        35554 non-null  object \n",
    " 13  scope_of_work             35554 non-null  object\n",
    "     'min', 'max'\n",
    " 14  access                    79    non-null  object \n",
    " 15  employer                  35554 non-null  object\n",
    "     'phone_number', 'email', 'url', 'organization_number', 'name', 'workplace'\n",
    " 16  application_details       35554 non-null  object \n",
    "     'information', 'reference', 'email', 'via_af', 'url', 'other'\n",
    " 17  experience_required       35554 non-null  bool   \n",
    " 18  access_to_own_car         35554 non-null  bool   \n",
    " 19  driving_license_required  35554 non-null  bool   \n",
    " 20  driving_license           7287  non-null  object \n",
    " 21  occupation                35554 non-null  object \n",
    " 22  occupation_group          35554 non-null  object \n",
    " 23  occupation_field          35554 non-null  object \n",
    " 24  workplace_address         35554 non-null  object\n",
    "     'municipality', 'municipality_code', 'municipality_concept_id', 'region', 'region_code', 'region_concept_id', 'country', 'country_code', 'country_concept_id', 'street_address', 'postcode', 'city', 'coordinates'\n",
    " 25  must_have                 35554 non-null  object\n",
    "     'skills', 'languages', 'work_experiences'\n",
    " 26  nice_to_have              35554 non-null  object \n",
    " 27  publication_date          35554 non-null  object X START DATE\n",
    " 28  last_publication_date     35554 non-null  object \n",
    " 29  removed                   35554 non-null  bool   \n",
    " 30  removed_date              0     non-null  object \n",
    " 31  source_type               35554 non-null  object \n",
    " 32  timestamp                 35554 non-null  int64 [---> Not available in 2009]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Function called to correct city column #### Makes all city strings lowercase for comparability ####\n",
    "#### In exploration alot of rows had '--' and '.' as city, using len statment we convert these to nan ####\n",
    "def correct(x):\n",
    "    try:\n",
    "        if len(x) <= 2:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return x.lower()\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting vars of interest from JSON files to decrease memory use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#### Converting the Monsters ####\n",
    "for i in range(2006,2020):\n",
    "    filename = '/Users/Kevin/Desktop/pb2006_2019/{}.json'.format(i)\n",
    "    with open(filename) as f:\n",
    "        ads = json.load(f)\n",
    "        new_list = []\n",
    "    \n",
    "    # Extracting vars of interest #\n",
    "    for ad in ads:\n",
    "        try:\n",
    "            x = [ad['headline'], ad['number_of_vacancies'], ad['publication_date'], ad['application_deadline'], ad['workplace_address']['city']]\n",
    "            new_list.append(x)\n",
    "        except:\n",
    "            x = [ad['headline'], ad['number_of_vacancies'], ad['publication_date'], ad['application_deadline'], np.nan]\n",
    "            new_list.append(x)\n",
    "\n",
    "    test = pd.DataFrame(new_list, columns=('headline','number_of_vacancies', 'publication_date', 'application_deadline', 'city'))\n",
    "    \n",
    "    # Correcting city format #\n",
    "    test['city'] = test['city'].apply(lambda x:correct(x))\n",
    "    \n",
    "    test.to_csv('/Users/Kevin/Desktop/pb2006_2019/select/{}'.format(+i), index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correcting date labels for 2018&2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_2018 = pd.read_csv('/Users/Kevin/Desktop/pb2006_2019/select/2018')\n",
    "t_2019 = pd.read_csv('/Users/Kevin/Desktop/pb2006_2019/select/2019')\n",
    "\n",
    "t_2018['publication_date'] = t_2018['publication_date'].apply(lambda x:x[0:11])\n",
    "t_2018['application_deadline'] = t_2018['application_deadline'].apply(lambda x:x[0:11])\n",
    "\n",
    "t_2019['publication_date'] = t_2019['publication_date'].apply(lambda x:x[0:11])\n",
    "t_2019['application_deadline'] = t_2019['application_deadline'].apply(lambda x:x[0:11])\n",
    "\n",
    "t_2018.to_csv('/Users/Kevin/Desktop/pb2006_2019/select/2018', index_label=False)\n",
    "t_2019.to_csv('/Users/Kevin/Desktop/pb2006_2019/select/2019', index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading in data and preparing datetime index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Result of extraction from JSON files ####\n",
    "t_2006 = pd.read_csv('/Users/Kevin/Desktop/pb2006_2019/select/2006')\n",
    "t_2007 = pd.read_csv('/Users/Kevin/Desktop/pb2006_2019/select/2007')\n",
    "t_2008 = pd.read_csv('/Users/Kevin/Desktop/pb2006_2019/select/2008')\n",
    "t_2009 = pd.read_csv('/Users/Kevin/Desktop/pb2006_2019/select/2009')\n",
    "t_2010 = pd.read_csv('/Users/Kevin/Desktop/pb2006_2019/select/2010')\n",
    "t_2011 = pd.read_csv('/Users/Kevin/Desktop/pb2006_2019/select/2011')\n",
    "t_2012 = pd.read_csv('/Users/Kevin/Desktop/pb2006_2019/select/2012')\n",
    "t_2013 = pd.read_csv('/Users/Kevin/Desktop/pb2006_2019/select/2013')\n",
    "t_2014 = pd.read_csv('/Users/Kevin/Desktop/pb2006_2019/select/2014')\n",
    "t_2015 = pd.read_csv('/Users/Kevin/Desktop/pb2006_2019/select/2015')\n",
    "t_2016 = pd.read_csv('/Users/Kevin/Desktop/pb2006_2019/select/2016')\n",
    "t_2017 = pd.read_csv('/Users/Kevin/Desktop/pb2006_2019/select/2017')\n",
    "t_2018 = pd.read_csv('/Users/Kevin/Desktop/pb2006_2019/select/2018')\n",
    "t_2019 = pd.read_csv('/Users/Kevin/Desktop/pb2006_2019/select/2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### All data lists ####\n",
    "all_years = [t_2006, t_2007, t_2008, t_2009, t_2010, t_2011, t_2012, t_2013, t_2014, t_2015, t_2016]\n",
    "all_years_10 = [t_2006, t_2007, t_2008, t_2009, t_2010]\n",
    "all_years_label = ['2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019']\n",
    "all_years_dict = {'2006': t_2006, '2007':t_2007, '2008':t_2008, '2009':t_2009, '2010':t_2010, '2011':t_2011, '2012':t_2012, '2013':t_2013, '2014':t_2014,'2015':t_2015,'2016':t_2016}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Concat all DF's into one big df ####\n",
    "t_2006_2010 = pd.concat(all_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "publication_date  application_deadline\n",
       "False             False                   4197574\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Removed all missing values ####\n",
    "t_2006_2010 = t_2006_2010[t_2006_2010.iloc[:,3].notnull() == True]\n",
    "t_2006_2010 = t_2006_2010[t_2006_2010.iloc[:,2].notnull() == True]\n",
    "t_2006_2010.iloc[:,[2,3]].isnull().value_counts() # No null values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Converting pub/dead col to datetime and sorting by publication_date ####\n",
    "t_2006_2010['publication_date'] = pd.to_datetime(t_2006_2010['publication_date'])\n",
    "t_2006_2010['application_deadline'] = pd.to_datetime(t_2006_2010['application_deadline'])\n",
    "t_2006_2010 = t_2006_2010.sort_values(by='publication_date')\n",
    "#### t_2006_2010_copy is our used df with datetime index ####\n",
    "t_2006_2010_copy = t_2006_2010.set_index(t_2006_2010['publication_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking active ads per day - Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Testing out DF slicing for smaller dfs ####\n",
    "#### As time moves closer to the present, number of ads increases significantly ####\n",
    "date = pd.to_datetime('2006-06-01')\n",
    "start_date = date+relativedelta(months=-3)\n",
    "end_date = date+relativedelta(months=+3)\n",
    "t_slice = t_2006_2010_copy.copy()\n",
    "t_slice = t_slice[start_date:end_date]\n",
    "t_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(2008, 2017):\n",
    "    for v in range(1,13):\n",
    "        results = []\n",
    "        # Date range for each month, calendar.monthrange sets days to last day in given month\n",
    "        date_range = pd.date_range('{}-{}-01'.format(i,v), '{}-{}-{}'.format(i, v, calendar.monthrange(int(i), v)[1]))\n",
    "        for date in date_range:\n",
    "            # Counter counts the number of ads active a given day\n",
    "            counter = 0\n",
    "            # We continuously create a 4-month moving window for each given day and check active ads\n",
    "            # This way we dont iterate through all 6.2 million ads but instead about 80-200k\n",
    "            start_date = date+relativedelta(months=-3)\n",
    "            end_date = date+relativedelta(months=+3)\n",
    "            t_slice = t_2006_2010_copy.copy()\n",
    "            t_slice = t_slice[start_date:end_date]\n",
    "            \n",
    "            for z in t_slice.iterrows():\n",
    "                if date in pd.date_range(start=z[1]['publication_date'], end=z[1]['application_deadline']):\n",
    "                    counter += z[1]['number_of_vacancies']\n",
    "            results.append([date, counter])\n",
    "        results_pd = pd.DataFrame(results)\n",
    "        results_pd.to_csv('/Users/Kevin/Desktop/pb2006_2019/final_L/{}{}'.format(i,v), index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_ads = 0\n",
    "jobs = 0\n",
    "for i in all_years:\n",
    "    job_ads += len(i)\n",
    "    jobs += i.iloc[:,1].sum()\n",
    "print('Total job ads:' + ' ' + str(job_ads))\n",
    "print('Total jobs:' + ' ' + str(jobs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#plt.style.use('seaborn')\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "\n",
    "for i in range(14):\n",
    "    fig.add_subplot(4,4,i+1)\n",
    "    sns.heatmap(all_years[i].isnull(), cbar=False, xticklabels=['hl','vacant','post_d','dead_d','city'])\n",
    "    plt.title(all_years_label[i])\n",
    "\n",
    "plt.savefig('/Users/Kevin/Desktop/MissingValues.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphical presentation of ads per day - Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd_result.to_csv('/Users/Kevin/Desktop/maj_jobb_test')\n",
    "#pd_result = pd.read_csv('/Users/Kevin/Desktop/pb2006_2019/tester/maj_jobb_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Customize x-axis date range #### 5D is simply five days between each tick ####\n",
    "date_index = pd.date_range('2006-05-01','2006-05-31', freq='5D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5.5,3.5))\n",
    "\n",
    "plt.plot(pd_result.iloc[:,0], pd_result.iloc[:,1])\n",
    "plt.plot(pd_result.iloc[:,0], pd_result['mean'], alpha=0.4, color='r')\n",
    "plt.xticks(date_index,rotation=90)\n",
    "\n",
    "plt.title('Lediga jobb 01-31/05/2006', loc='left',fontweight='heavy')\n",
    "\n",
    "plt.savefig('/Users/Kevin/Desktop/Jobb.svg', bbox_inches='tight', facecolor=fig.get_facecolor(), edgecolor='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
