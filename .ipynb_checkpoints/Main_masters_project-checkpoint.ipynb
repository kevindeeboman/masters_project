{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Project imports ###\n",
    "import pandas as pd\n",
    "import psycopg2 as pg2\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "import calendar\n",
    "from calendar import monthrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project overview\n",
    "#### Objective: Create a historic daily labor demand index based of total available jobs for a given day between 2006-2020      \n",
    "- In this project, only job ads from Arbetsf√∂rmedlingen (JobTechDev) will be used. In a future project, current labor demand index will be constructed and supplemented with ads through the means of web scraping.\n",
    "    \n",
    "- Statistics from the European Commission[<sup>1</sup>](#fn1) shows that the percentage of job seekers using public employment services in EU-countries is among the highest in Sweden, above 70%. Thus, the index may be a good complement to official statistics in measuring labor demand.\n",
    "    \n",
    "- Performace of the index will be evaluated through comparison to Swedens official statistics (survey index).\n",
    "\n",
    "#### Project steps\n",
    "- Step 1: Converting JSON files to CSV and extracting relevant data (+data cleaning).\n",
    "- Step 2: Inserting data into a postgreSQL database and setting up relevant query.\n",
    "- Step 3: Visualizing and discussion of results.\n",
    "\n",
    "<span id=\"fn1\"> footnote 1</span>: European Commission (2017) [European Semester Thematic Factsheet](https://wayback.archive-it.org/12090/20201012083437/https://ec.europa.eu/info/sites/info/files/european-semester_thematic-factsheet_public-employment-services_en_0.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Converting JSON files to CSV and extracting relevant data (+ data cleaning)\n",
    "#### All data used in this project is from [JobTechDev](https://jobtechdev.se/docs/apis/historical/), an initiative by the Swedish public employment service.\n",
    "- The complete dataset is about 30.8 GB and files are in the JSON-format\n",
    "- Dataset contains 32 differerent columns/vars, many of which are beyond the scope of the project, as such a selection will be extracted.\n",
    "\n",
    "- Variables to be extracted for this project are the following:\n",
    "    - headline: The ad headline\n",
    "    - number_of_vacancies: The number of advertised jobs for ad\n",
    "    - publication_date: Date the ad was published on the job ad platform\n",
    "    - application_deadline: The last date to apply for the job\n",
    "    - last_publication_date: The last date the ad was public, used as substitutet for application deadline for 2017 where application_deadline is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_valid = 0; total_errors = 0\n",
    "for file in range(2015,2021):\n",
    "    filename = f'/Users/Kevin/Desktop/project_dta/json_pb2006_2020/{file}.json'\n",
    "    with open(filename) as f:\n",
    "        ads = json.load(f)\n",
    "        file_ads = []\n",
    "        error_rows = 0\n",
    "        \n",
    "    # For 2017 application_deadline is null, last_publication_date used as a proxy, vars 99.8% equivalent #\n",
    "    for ad in ads:\n",
    "        # Removal of special characters, events of \\n causes errors in csv file #\n",
    "        head_line = re.sub('[!,*)@#%(&$_?.^\\\\\\\\\\n/]', '', str(ad['headline']))\n",
    "        if file != 2017:\n",
    "            try:\n",
    "                ad_select = [head_line, int(ad['number_of_vacancies']), ad['publication_date'][:10], ad['application_deadline'][:10]]\n",
    "            except:\n",
    "                error_rows += 1\n",
    "                continue\n",
    "        else:\n",
    "            try:\n",
    "                ad_select = [head_line, int(ad['number_of_vacancies']), ad['publication_date'][:10], ad['last_publication_date'][:10]]    \n",
    "            except:\n",
    "                error_rows += 1\n",
    "                continue\n",
    "                \n",
    "        # Jobs ads with no vacancies or missing values in date/vacancies removed, headlines of less importance #\n",
    "        if int(ad['number_of_vacancies']) > 0 and all(ad_select[1:]):\n",
    "            file_ads.append(ad_select)\n",
    "        else:\n",
    "            error_rows += 1\n",
    "            continue\n",
    "\n",
    "    # We write the extracted data to a CSV-file for easy insertion into PostgreSQL #             \n",
    "    with open(f'/Users/Kevin/Desktop/project_dta/csv_pd2006_2020/{file}.csv', mode='w', newline=\"\") as file_writer:\n",
    "        write = csv.writer(file_writer)\n",
    "        for row in file_ads:\n",
    "            write.writerow(row)\n",
    "    print(f'vaild ads for {file}: ' + str(len(file_ads)))\n",
    "    print(f'erroneous ads for {file}: ' + str(error_rows))\n",
    "    total_valid += len(file_ads); total_errors += error_rows\n",
    "print('\\n')\n",
    "print('total valid ads: ' + str(total_valid))\n",
    "print('total erroneous ads: '+ str(total_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As the above output shows, we have a total of x ads between 2006-2020\n",
    "* Between 2018-2020 data seems to have been cleaned before publication as few ads are erroneous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Inserting data into a postgreSQL database and setting up relevant query\n",
    " - To efficiently work with the data, it will be imported into postgreSQL for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB created in pgAdmin4 GUI, login and connect cursor #\n",
    "conn = pg2.connect(database='job_ads', user='postgres', password='********')\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table creation #\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE historic_final_f(\n",
    "    ad_id SERIAL PRIMARY KEY,\n",
    "    headline VARCHAR,\n",
    "    number_of_vacancies INTEGER NOT NULL,\n",
    "    publication_date DATE NOT NULL,\n",
    "    application_deadline DATE NOT NULL);\"\"\")\n",
    "# Changes to a DB must be followed witha a commit() statement, otherwise rollback() #\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing csv files into PostgreSQL #\n",
    "for file in range(2006, 2021):\n",
    "    with open(f'/Users/Kevin/Desktop/project_dta/csv_pd2006_2020/{file}.csv', 'r') as csv_file:\n",
    "        cur.copy_from(csv_file, 'historic_final_f', sep=',', columns=('headline', 'number_of_vacancies', 'publication_date', 'application_deadline'))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the cell below we check, for each day between 2006 and 2020, how many ads were active the given day and then we sum the number och vacancies in these ads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacancies_per_day = []\n",
    "for year in range(2006, 2021):\n",
    "    for month in range(1,13):\n",
    "        for day in range(1, calendar.monthrange(year, month)[1]):\n",
    "            cur.execute(f\"\"\"\n",
    "SELECT SUM(number_of_vacancies) FROM historic_final_f WHERE '{year}-{month}-{day}' >= publication_date AND '{year}-{month}-{day}' <= application_deadline;\n",
    "\"\"\")\n",
    "            data = cur.fetchone()\n",
    "            ads_day = [f'{year}-{month}-{day}', int(data[0])]\n",
    "            print(ads_day)\n",
    "            vacancies_per_day.append(ads_day)\n",
    "\n",
    "with open(f'/Users/Kevin/Desktop/project_dta/csv_pd2006_2020/results.csv', mode='w', newline=\"\") as file_writer:\n",
    "    write = csv.writer(file_writer)\n",
    "    for row in vacancies_per_day:\n",
    "        write.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Visualizing and discussion of results\n",
    "#### As mentioned, the comparison data is from Statistics Sweden and can be collected \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5.5,3.5))\n",
    "\n",
    "plt.plot(pd_result.iloc[:,0], pd_result.iloc[:,1])\n",
    "plt.plot(pd_result.iloc[:,0], pd_result['mean'], alpha=0.4, color='r')\n",
    "plt.xticks(date_index,rotation=90)\n",
    "\n",
    "plt.title('Lediga jobb 01-31/05/2006', loc='left',fontweight='heavy')\n",
    "\n",
    "# plt.savefig('/Users/Kevin/Desktop/Jobb.svg', bbox_inches='tight', facecolor=fig.get_facecolor(), edgecolor='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
