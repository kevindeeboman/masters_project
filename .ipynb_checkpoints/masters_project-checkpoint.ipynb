{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Project imports ###\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2 as pg2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project overview\n",
    "#### Objective: Create a historic daily labor demand index based of total available jobs for a given day between 2006-2020  \n",
    "    - In this project, only job ads from Arbetsf√∂rmedlingen (JobTechDev) will be used. In a future project, current labor demand index will be constructed and supplemented with ads through the means of web scraping.\n",
    "    \n",
    "    - Performace of the index will be evaluated through comparison to Swedens official statistics (survey index)\n",
    "#### Project steps\n",
    "       - Step 1: Converting JSON files to CSV and extracting relevant data (+data cleaning)\n",
    "       - Step 2: Inserting data into a postgreSQL database and setting up relevant query\n",
    "       - Step 3: Visualizing and discussing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Converting JSON files to CSV and extracting relevant data (+ data cleaning)\n",
    "#### All data used in this project is from [JobTechDev](https://jobtechdev.se/docs/apis/historical/)  \n",
    "    - The complete dataset is about 30.8GB and files are in the JSON-format\n",
    "    - Dataset contains 32 differerent columns/vars, many of which are beyond the scope of the project, as such a selection will be extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_dfs = []\n",
    "for file in range(2006,2007):\n",
    "    filename = f'/Users/Kevin/Desktop/project_dta/json_pb2006_2020/{file}.json'\n",
    "    with open(filename) as f:\n",
    "        ads = json.load(f)\n",
    "        file_ads = []\n",
    "    \n",
    "    # For 2017 application_deadline is null, last_publication_date used as a proxy, vars 99.8% equivalent #\n",
    "    for ad in ads:\n",
    "            if file != 2017:\n",
    "                ad_select = [ad['headline'], ad['number_of_vacancies'], ad['publication_date'], ad['application_deadline']]\n",
    "                file_ads.append(ad_select)\n",
    "            else:\n",
    "                ad_select = [ad['headline'], ad['number_of_vacancies'], ad['publication_date'], ad['last_publication_date']]\n",
    "                file_ads.append(ad_select)\n",
    "    \n",
    "    file_df = pd.DataFrame(file_ads, columns=('headline','number_of_vacancies', 'publication_date', 'application_deadline'))\n",
    "\n",
    "    # Date for 2018-2020 includes time in the date columns, we slice to only keep the format 'YYYY-MM-DD' #\n",
    "    if file in [2018, 2019, 2020]:\n",
    "        file_df['publication_date'] = file_df['publication_date'].apply(lambda x:x[0:11])\n",
    "        file_df['application_deadline'] = file_df['application_deadline'].apply(lambda x:x[0:11])\n",
    "    #all_dfs.append(file_df)\n",
    "    file_df.to_csv(f'/Users/Kevin/Desktop/project_dta/csv_pd2006_2020/{file}', index=False, index_label=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.style.use('seaborn')\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "sns.heatmap(file_df.isnull(), cbar=False, xticklabels=['hl','vacant','post_d','dead_d'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Inserting data into a postgreSQL database and setting up relevant query\n",
    "    - To efficiently work with the data, it will be imported into postgreSQL for analysis, query results will then be analyzed in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DB created in pgAdmin4 GUI, table specifications below ###\n",
    "conn = pg2.connect(database='job_ads', user='postgres', password='World930920')\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Table creation ###\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE historic_ads (\n",
    "    ad_id SERIAL PRIMARY KEY,\n",
    "    headline VARCHAR NOT NULL,\n",
    "    number_of_vacancies INTEGER NOT NULL,\n",
    "    publication_date DATE NOT NULL,\n",
    "    application_deadline DATE NOT NULL);\"\"\")\n",
    "\n",
    "\n",
    "#sqlCreateTable = \"create table \"+name_Table+\" (id bigint, title varchar(128), summary varchar(256), story text);\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fetch data from cursor, use tab to get all options (fetchone, fetchmany, fetchall)\n",
    "data = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empt_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### With the cursor execute some command\n",
    "\n",
    "cur.execute(f\"\"\"\n",
    "SELECT * FROM payment\n",
    "WHERE payment_date BETWEEN '2005-01-01' AND '2007-05-01'\n",
    "\"\"\")\n",
    "data = cur.fetchall()\n",
    "for i in data:\n",
    "    ### We use tuple unpacking to get our vars\n",
    "    (payment_id, customer_id, staff_id, rental_id, amount, payment_date) = i\n",
    "    empt_list.append([payment_id, customer_id, staff_id, rental_id, amount, payment_date])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### List can then be stored as a new df\n",
    "x = pd.DataFrame(empt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
